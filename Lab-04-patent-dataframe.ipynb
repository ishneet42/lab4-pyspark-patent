{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   NULL|     BE|   NULL|    NULL|      1|  NULL|   269|  6|    69| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070802| 1963| 1096|   NULL|     US|     TX|    NULL|      1|  NULL|     2|  6|    63| NULL|       0|    NULL|   NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070803| 1963| 1096|   NULL|     US|     IL|    NULL|      1|  NULL|     2|  6|    63| NULL|       9|    NULL| 0.3704|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070804| 1963| 1096|   NULL|     US|     OH|    NULL|      1|  NULL|     2|  6|    63| NULL|       3|    NULL| 0.6667|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070805| 1963| 1096|   NULL|     US|     CA|    NULL|      1|  NULL|     2|  6|    63| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We create a smaller DataFrame called \"patents_states\" containing only PATENT, COUNTRY, POSTATE\n",
    "\n",
    "### These are the columns we’ll need later to check if citations happen within the same state.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "| PATENT|COUNTRY|POSTATE|\n",
      "+-------+-------+-------+\n",
      "|3070801|     BE|   NULL|\n",
      "|3070802|     US|     TX|\n",
      "|3070803|     US|     IL|\n",
      "|3070804|     US|     OH|\n",
      "|3070805|     US|     CA|\n",
      "+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents_states = patents.select(\"PATENT\", \"COUNTRY\", \"POSTATE\")\n",
    "patents_states.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We rename columns in patents_states to avoid conflicts later (PC_PATENT, PC_POSTATE).  \n",
    "### Then we do a join. \n",
    "- Match citations.CITED with PC_PATENT.  \n",
    "- This gives us the state information of the cited patent.  \n",
    "\n",
    "Now each citation row includes where the cited patent is from.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|CITING |CITED  |PC_POSTATE|\n",
      "+-------+-------+----------+\n",
      "|3858242|1515701|NULL      |\n",
      "|3858242|3319261|OH        |\n",
      "|3858241|3634889|OH        |\n",
      "|3858241|956203 |NULL      |\n",
      "|3858241|1324234|NULL      |\n",
      "|3858243|2949611|NULL      |\n",
      "|3858243|3146465|MI        |\n",
      "|3858241|3398406|FL        |\n",
      "|3858241|3557384|MA        |\n",
      "|3858242|3668705|WI        |\n",
      "+-------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pc = patents_states.withColumnRenamed(\"PATENT\", \"PC_PATENT\") \\\n",
    "                   .withColumnRenamed(\"POSTATE\", \"PC_POSTATE\") \\\n",
    "                   .withColumnRenamed(\"COUNTRY\", \"PC_COUNTRY\")\n",
    "\n",
    "cited_join = citations.join(pc, citations.CITED == col(\"PC_PATENT\"), how=\"left\")\n",
    "\n",
    "# show the joined table (example)\n",
    "cited_join.select(\"CITING\", \"CITED\", \"PC_POSTATE\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do a second join, this time renaming columns to P2_PATENT, P2_POSTATE.  \n",
    "We join citations.CITING with P2_PATENT.  \n",
    "\n",
    "Now each row has both:  \n",
    "- The state of the cited patent (PC_POSTATE)  \n",
    "- The state of the citing patent (P2_POSTATE)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+\n",
      "|CITING |CITED  |PC_POSTATE|P2_POSTATE|\n",
      "+-------+-------+----------+----------+\n",
      "|3858242|1515701|NULL      |MI        |\n",
      "|3858242|3319261|OH        |MI        |\n",
      "|3858242|3668705|WI        |MI        |\n",
      "|3858242|3707004|WI        |MI        |\n",
      "|3858243|2949611|NULL      |NULL      |\n",
      "|3858243|3146465|MI        |NULL      |\n",
      "|3858241|3634889|OH        |MA        |\n",
      "|3858241|956203 |NULL      |MA        |\n",
      "|3858241|1324234|NULL      |MA        |\n",
      "|3858241|3398406|FL        |MA        |\n",
      "+-------+-------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = patents_states.withColumnRenamed(\"PATENT\", \"P2_PATENT\") \\\n",
    "                   .withColumnRenamed(\"POSTATE\", \"P2_POSTATE\") \\\n",
    "                   .withColumnRenamed(\"COUNTRY\", \"P2_COUNTRY\")\n",
    "\n",
    "cited_citing_join = cited_join.join(p2, cited_join.CITING == col(\"P2_PATENT\"), how=\"left\")\n",
    "\n",
    "cited_citing_join.select(\"CITING\", \"CITED\", \"PC_POSTATE\", \"P2_POSTATE\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We clean and filter the data:  \n",
    "- Remove empty state values.  \n",
    "- Convert state codes to uppercase (to avoid mismatch like \"ca\" vs \"CA\").  \n",
    "- Keep only rows where PC_POSTATE == P2_POSTATE.  \n",
    "\n",
    "The result is citations where both patents are from the same U.S. state.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+\n",
      "|CITING |CITED  |PC_POSTATE|P2_POSTATE|\n",
      "+-------+-------+----------+----------+\n",
      "|4178878|3464385|AK        |AK        |\n",
      "|3974004|3745074|AL        |AL        |\n",
      "|3974004|3585090|AL        |AL        |\n",
      "|3974004|3692600|AL        |AL        |\n",
      "|3974004|3762972|AL        |AL        |\n",
      "|4554823|3373564|AL        |AL        |\n",
      "|4698246|3972467|AL        |AL        |\n",
      "|4701360|3972467|AL        |AL        |\n",
      "|5078406|5026073|AL        |AL        |\n",
      "|5701722|5623808|AL        |AL        |\n",
      "+-------+-------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim, upper\n",
    "\n",
    "filtered = cited_citing_join.filter(\n",
    "    (trim(col(\"PC_POSTATE\")) != \"\") &\n",
    "    (trim(col(\"P2_POSTATE\")) != \"\") &\n",
    "    (upper(trim(col(\"PC_POSTATE\"))) == upper(trim(col(\"P2_POSTATE\"))))\n",
    ")\n",
    "\n",
    "filtered = filtered.cache()\n",
    "\n",
    "filtered.select(\"CITING\", \"CITED\", \"PC_POSTATE\", \"P2_POSTATE\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the cnt DataFrame (counts) with the main patents DataFrame.  \n",
    "- If a patent doesn’t appear in cnt, we fill its SAME_STATE count with 0 (coalesce).  \n",
    "- Finally, we sort patents by SAME_STATE in descending order.  \n",
    "\n",
    "The result shows the top patents that cite the most within their own state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|CITING |SAME_STATE|\n",
      "+-------+----------+\n",
      "|4240165|3         |\n",
      "|5096364|2         |\n",
      "|5122917|5         |\n",
      "|5203482|2         |\n",
      "|5583013|9         |\n",
      "|5409826|2         |\n",
      "|4053654|1         |\n",
      "|4829378|1         |\n",
      "|5393360|2         |\n",
      "|4781565|2         |\n",
      "+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "cnt = filtered.groupBy(\"CITING\").agg(count(\"*\").alias(\"SAME_STATE\"))\n",
    "\n",
    "cnt.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1.0     |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125       |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0.0     |0.0     |NULL    |NULL    |103       |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1.0     |NULL   |0.7415  |NULL    |5.0     |0.0085  |0.0083  |NULL    |NULL    |100       |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1.0     |NULL   |0.7442  |NULL    |5.1102  |0.0     |0.0     |NULL    |NULL    |98        |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1.0     |NULL   |0.7397  |NULL    |5.181   |0.0     |0.0     |NULL    |NULL    |96        |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1.0     |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96        |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1.0     |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94        |\n",
      "|5739256|1998 |13983|1995   |US     |CA     |70060   |2      |15    |528   |1  |15    |453  |0       |1.0     |NULL   |0.8232  |NULL    |15.1104 |0.1124  |0.1082  |NULL    |NULL    |90        |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7403  |NULL    |8.3595  |0.0     |0.0     |NULL    |NULL    |90        |\n",
      "|5978329|1999 |14550|1995   |US     |CA     |148925  |2      |NULL  |369   |2  |24    |145  |0       |1.0     |NULL   |0.5449  |NULL    |12.9241 |0.4196  |0.4138  |NULL    |NULL    |90        |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "augmented = patents.join(cnt, patents.PATENT == cnt.CITING, how=\"left\").drop(\"CITING\")\n",
    "augmented = augmented.withColumn(\"SAME_STATE\", coalesce(col(\"SAME_STATE\"), lit(0)))\n",
    "\n",
    "top10 = augmented.orderBy(col(\"SAME_STATE\").desc()).select(\"*\")\n",
    "top10.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
