{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import csv \n",
    "import io\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset and viewig the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully\n",
      "Sample citations: ['\"CITING\",\"CITED\"', '3858241,956203', '3858241,1324234']\n",
      "Sample patents: ['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"', '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,', '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,']\n"
     ]
    }
   ],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")\n",
    "\n",
    "print(\"Datasets loaded successfully\")\n",
    "print(\"Sample citations:\", rddCitations.take(3))\n",
    "print(\"Sample patents:\", rddPatents.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## step 1: parsing citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This helper function splits a line of text into fields using Python’s CSV reader.  \n",
    "- It handles commas inside quotes correctly.  \n",
    "- If parsing fails, it returns an empty list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fields(text_line):\n",
    "    try:\n",
    "        return next(csv.reader(io.StringIO(text_line)))\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function parses a single line of the citation file.  \n",
    "- Skips the header and malformed rows.  \n",
    "- Returns a tuple (citing_id, cited_id) as integers (Convert a citations record into (citing, cited).)\n",
    "- Returns None if line is header or malformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_citations(line):\n",
    "    parts = split_fields(line)\n",
    "    if not parts or parts[0] == \"CITING\":\n",
    "        return None\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    try:\n",
    "        citing_id = int(parts[0])\n",
    "        cited_id = int(parts[1])\n",
    "        return (citing_id, cited_id)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function parses a line of the patent file\n",
    "- Extracts (patent_id, state) but only if the patent is from the US and has a state.  \n",
    "- Skips patents from other countries or with missing state info.\n",
    "- Returns None otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_patents(line):\n",
    "    parts = split_fields(line)\n",
    "    if not parts or parts[0] == \"PATENT\":\n",
    "        return None\n",
    "    if len(parts) < 6:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        pid = int(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    country = parts[4].strip('\"') if len(parts) > 4 else \"\"\n",
    "    state = parts[5].strip('\"') if len(parts) > 5 else \"\"\n",
    "    \n",
    "    if country == \"US\" and state:\n",
    "        return (pid, state)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function extracts the entire row of patent information, keyed by patent ID.  \n",
    "- Useful later to display detailed info about important patents.\n",
    "- Ensures rows have at least 23 fields.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing utilities loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def parse_full_patent_info(line):\n",
    "    parts = split_fields(line)\n",
    "    if not parts or parts[0] == \"PATENT\":\n",
    "        return None\n",
    "    if len(parts) < 23:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        pid = int(parts[0])\n",
    "        return (pid, parts)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "print(\"Parsing utilities loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We process the citations RDD:  \n",
    "- Apply parse_citations.  \n",
    "- Filter out None values.  \n",
    "- Cache the result for reuse.  \n",
    "- Show the total count and a small sample.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed citations count: 16522438\n",
      "Sample: [(3858241, 956203), (3858241, 1324234), (3858241, 3398406), (3858241, 3557384), (3858241, 3634889)]\n"
     ]
    }
   ],
   "source": [
    "citations_parsed = rddCitations.map(parse_citations).filter(lambda x: x).cache()\n",
    "print(f\"Parsed citations count: {citations_parsed.count()}\")\n",
    "print(\"Sample:\", citations_parsed.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: parsing patents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We process the patents RDD:  \n",
    "- Apply parse_patents.  \n",
    "- Keep only valid (patent_id, state) pairs.  \n",
    "- Cache the result.  \n",
    "- Show how many such patents exist and a small sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed US patents with state count: 1784989\n",
      "Sample: [(3070802, 'TX'), (3070803, 'IL'), (3070804, 'OH'), (3070805, 'CA'), (3070806, 'PA')]\n"
     ]
    }
   ],
   "source": [
    "patents_parsed = rddPatents.map(parse_patents).filter(lambda x: x).cache()\n",
    "print(f\"Parsed US patents with state count: {patents_parsed.count()}\")\n",
    "print(\"Sample:\", patents_parsed.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: creating state lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We convert the parsed patents into a Python dictionary using collectAsMap().  \n",
    "- Key = patent ID.  \n",
    "- Value = state code.  \n",
    "This gives fast lookups for finding a patent’s state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent to state mapping created with 1784989 entries\n",
      "Sample: [(3070802, 'TX'), (3070803, 'IL'), (3070804, 'OH'), (3070805, 'CA'), (3070806, 'PA')]\n"
     ]
    }
   ],
   "source": [
    "map_patent_to_state = patents_parsed.collectAsMap()\n",
    "print(f\"Patent to state mapping created with {len(map_patent_to_state)} entries\")\n",
    "print(\"Sample:\", list(map_patent_to_state.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: filter citations should include those with both states availabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We enrich each citation with state info for both patents:  \n",
    "- (citing, cited, citing_state, cited_state) \n",
    "- Only keep citations where both patents have state information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations with both states count: 6920796\n",
      "Sample: [(3858241, 3398406, 'MA', 'FL'), (3858241, 3557384, 'MA', 'MA'), (3858241, 3634889, 'MA', 'OH'), (3858242, 3319261, 'MI', 'OH'), (3858242, 3668705, 'MI', 'WI')]\n"
     ]
    }
   ],
   "source": [
    "def filter_citations_with_states(citation):\n",
    "    citing, cited = citation\n",
    "    if citing in map_patent_to_state and cited in map_patent_to_state:\n",
    "        return (citing, cited, map_patent_to_state[citing], map_patent_to_state[cited])\n",
    "    return None\n",
    "\n",
    "citations_with_states = citations_parsed.map(filter_citations_with_states).filter(lambda x: x).cache()\n",
    "print(f\"Citations with both states count: {citations_with_states.count()}\")\n",
    "print(\"Sample:\", citations_with_states.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5: filter for self state citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter to keep only citations where both patents are from the same state.  \n",
    "- These are called “self-state citations.”  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-state citations count: 1488330\n",
      "Sample: [(3858241, 3557384, 'MA', 'MA'), (3858245, 3755824, 'NY', 'NY'), (3858247, 3621837, 'CA', 'CA'), (3858247, 3694819, 'CA', 'CA'), (3858249, 3418664, 'TX', 'TX')]\n"
     ]
    }
   ],
   "source": [
    "def is_self_state_citation(cws):\n",
    "    citing, cited, citing_state, cited_state = cws\n",
    "    return citing_state == cited_state\n",
    "\n",
    "self_state_citations = citations_with_states.filter(is_self_state_citation).cache()\n",
    "print(f\"Self-state citations count: {self_state_citations.count()}\")\n",
    "print(\"Sample:\", self_state_citations.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 6: count self state citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We transform each self-state citation into (citing_id, 1) and then sum counts per patent using reduceByKey.  \n",
    "- The result is: for each citing patent, how many same-state citations it made.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patents with self-state citations count: 571919\n",
      "Sample: [(3858241, 1), (3858245, 1), (3858247, 2), (3858249, 4), (3858251, 1)]\n"
     ]
    }
   ],
   "source": [
    "def extract_citing_patent(cws):\n",
    "    citing, cited, citing_state, cited_state = cws\n",
    "    return (citing, 1)\n",
    "\n",
    "self_state_counts = self_state_citations.map(extract_citing_patent).reduceByKey(operator.add).cache()\n",
    "print(f\"Patents with self-state citations count: {self_state_counts.count()}\")\n",
    "print(\"Sample:\", self_state_counts.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 7: top 10 reuslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 patents (patent_id, same-state citation count):\n",
      "1. 5959466 → 125\n",
      "2. 5983822 → 103\n",
      "3. 6008204 → 100\n",
      "4. 5952345 → 98\n",
      "5. 5958954 → 96\n",
      "6. 5998655 → 96\n",
      "7. 5936426 → 94\n",
      "8. 5739256 → 90\n",
      "9. 5913855 → 90\n",
      "10. 5925042 → 90\n"
     ]
    }
   ],
   "source": [
    "top_10_counts = self_state_counts.takeOrdered(10, key=lambda x: -x[1])\n",
    "print(\"Top 10 patents (patent_id, same-state citation count):\")\n",
    "for i, (pid, cnt) in enumerate(top_10_counts, 1):\n",
    "    print(f\"{i}. {pid} → {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 8: creating formatted table and printing top 10 patent infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent 5959466 (CA) → 125 same-state citations\n",
      "Patent 5983822 (TX) → 103 same-state citations\n",
      "Patent 6008204 (CA) → 100 same-state citations\n",
      "Patent 5952345 (CA) → 98 same-state citations\n",
      "Patent 5958954 (CA) → 96 same-state citations\n",
      "Patent 5998655 (CA) → 96 same-state citations\n",
      "Patent 5936426 (CA) → 94 same-state citations\n",
      "Patent 5739256 (CA) → 90 same-state citations\n",
      "Patent 5913855 (CA) → 90 same-state citations\n",
      "Patent 5925042 (CA) → 90 same-state citations\n"
     ]
    }
   ],
   "source": [
    "top_ids = [pid for pid, _ in top_10_counts]\n",
    "\n",
    "top_detailed = rddPatents.map(parse_full_patent_info) \\\n",
    "    .filter(lambda x: x and x[0] in top_ids) \\\n",
    "    .collectAsMap()\n",
    "\n",
    "for pid, cnt in sorted(top_10_counts, key=lambda x: -x[1]):\n",
    "    if pid in top_detailed:\n",
    "        row = top_detailed[pid]\n",
    "        print(f\"Patent {row[0]} ({row[5]}) → {cnt} same-state citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+--------+------+------+--------+--------+--------+---------+--------+-------+-------+----+-------+------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+-----------+\n",
      "|PATENT  |GYEAR |GDATE |APPYEAR |COUNTRY |POSTATE |ASSIGNEE |ASSCODE |CLAIMS |NCLASS |CAT |SUBCAT |CMADE |CRECEIVE |RATIOCIT |GENERAL |ORIGINAL |FWDAPLAG |BCKGTLAG |SELFCTUB |SELFCTLB |SECDUPBD |SECDLWBD |SAME_STATE |\n",
      "+--------+------+------+--------+--------+--------+---------+--------+-------+-------+----+-------+------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+-----------+\n",
      "|5959466 |1999  |14515 |1997    |US      |CA      |5310     |2       |null   |326    |4   |46     |159   |0        |1        |null    |0.6186   |null     |4.8868   |0.0455   |0.044    |null     |null     |125        |\n",
      "|5983822 |1999  |14564 |1998    |US      |TX      |569900   |2       |null   |114    |5   |55     |200   |0        |0.995    |null    |0.7201   |null     |12.45    |0        |0        |null     |null     |103        |\n",
      "|6008204 |1999  |14606 |1998    |US      |CA      |749584   |2       |null   |514    |3   |31     |121   |0        |1        |null    |0.7415   |null     |5        |0.0085   |0.0083   |null     |null     |100        |\n",
      "|5952345 |1999  |14501 |1997    |US      |CA      |749584   |2       |null   |514    |3   |31     |118   |0        |1        |null    |0.7442   |null     |5.1102   |0        |0        |null     |null     |98         |\n",
      "|5958954 |1999  |14515 |1997    |US      |CA      |749584   |2       |null   |514    |3   |31     |116   |0        |1        |null    |0.7397   |null     |5.181    |0        |0        |null     |null     |96         |\n",
      "|5998655 |1999  |14585 |1998    |US      |CA      |null     |1       |null   |560    |1   |14     |114   |0        |1        |null    |0.7387   |null     |5.1667   |null     |null     |null     |null     |96         |\n",
      "|5936426 |1999  |14466 |1997    |US      |CA      |5310     |2       |null   |326    |4   |46     |178   |0        |1        |null    |0.58     |null     |11.2303  |0.0765   |0.073    |null     |null     |94         |\n",
      "|5739256 |1998  |13983 |1995    |US      |CA      |70060    |2       |15     |528    |1   |15     |453   |0        |1        |null    |0.8232   |null     |15.1104  |0.1124   |0.1082   |null     |null     |90         |\n",
      "|5913855 |1999  |14417 |1997    |US      |CA      |733846   |2       |null   |606    |3   |32     |242   |0        |1        |null    |0.7403   |null     |8.3595   |0        |0        |null     |null     |90         |\n",
      "|5925042 |1999  |14445 |1997    |US      |CA      |733846   |2       |null   |606    |3   |32     |242   |0        |1        |null    |0.7382   |null     |8.3471   |0        |0        |null     |null     |90         |\n",
      "+--------+------+------+--------+--------+--------+---------+--------+-------+-------+----+-------+------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    (\"PATENT\", 8), (\"GYEAR\", 6), (\"GDATE\", 6), (\"APPYEAR\", 8),\n",
    "    (\"COUNTRY\", 8), (\"POSTATE\", 8), (\"ASSIGNEE\", 9), (\"ASSCODE\", 8),\n",
    "    (\"CLAIMS\", 7), (\"NCLASS\", 7), (\"CAT\", 4), (\"SUBCAT\", 7),\n",
    "    (\"CMADE\", 6), (\"CRECEIVE\", 9), (\"RATIOCIT\", 9), (\"GENERAL\", 8),\n",
    "    (\"ORIGINAL\", 9), (\"FWDAPLAG\", 9), (\"BCKGTLAG\", 9), (\"SELFCTUB\", 9),\n",
    "    (\"SELFCTLB\", 9), (\"SECDUPBD\", 9), (\"SECDLWBD\", 9), (\"SAME_STATE\", 11)\n",
    "]\n",
    "\n",
    "sep_line = \"+\" + \"+\".join(\"-\" * w for _, w in columns) + \"+\"\n",
    "header_line = \"|\" + \"|\".join(name.ljust(w) for name, w in columns) + \"|\"\n",
    "\n",
    "print()\n",
    "print(sep_line)\n",
    "print(header_line)\n",
    "print(sep_line)\n",
    "\n",
    "patent_to_count = dict(top_10_counts)\n",
    "sorted_patents = sorted(top_10_counts, key=lambda x: -x[1])\n",
    "\n",
    "for pid, count in sorted_patents:\n",
    "    if pid not in top_detailed:\n",
    "        continue\n",
    "    \n",
    "    row = top_detailed[pid]\n",
    "\n",
    "    def safe_val(v):\n",
    "        if v is None or str(v).strip() == \"\":\n",
    "            return \"null\"\n",
    "        return str(v).strip('\"')\n",
    "\n",
    "    values = [\n",
    "        safe_val(row[0]), safe_val(row[1]), safe_val(row[2]), safe_val(row[3]),\n",
    "        safe_val(row[4]), safe_val(row[5]), safe_val(row[6]), safe_val(row[7]),\n",
    "        safe_val(row[8]), safe_val(row[9]), safe_val(row[10]), safe_val(row[11]),\n",
    "        safe_val(row[12]), safe_val(row[13]), safe_val(row[14]), safe_val(row[15]),\n",
    "        safe_val(row[16]), safe_val(row[17]), safe_val(row[18]), safe_val(row[19]),\n",
    "        safe_val(row[20]), safe_val(row[21]), safe_val(row[22]), str(count)\n",
    "    ]\n",
    "    \n",
    "    formatted = \"|\" + \"|\".join(val.ljust(w) for val, (_, w) in zip(values, columns)) + \"|\"\n",
    "    print(formatted)\n",
    "\n",
    "print(sep_line)\n",
    "print(\"only showing top 10 rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
